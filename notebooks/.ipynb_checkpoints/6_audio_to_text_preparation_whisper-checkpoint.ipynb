{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c84e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6_audio_to_text_preparation_whisper.ipynb\n",
    "\"\"\"\n",
    "Prepare audio-to-text training data from Indigenous language recordings using OpenAI's Whisper.\n",
    "Includes segmentation, transcription, and export to plain text for LLM fine-tuning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5a5e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üì¶ Step 1: Install dependencies (run once)\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install ffmpeg-python pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f2296",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# üß† Step 2: Import libraries\n",
    "import whisper\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ffb55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# üìÇ Step 3: Set your data directory\n",
    "audio_dir = \"../datasets/audio/\"  # Your audio files here (.mp3, .wav, etc.)\n",
    "output_dir = \"../datasets/audio_transcripts/\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1ea0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# üì¶ Step 4: Load Whisper model\n",
    "# Choose from: tiny, base, small, medium, large (larger = more accurate)\n",
    "model_size = \"small\"\n",
    "model = whisper.load_model(model_size)\n",
    "print(f\"‚úÖ Whisper {model_size} model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77240f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# üéß Step 5: Transcribe audio files\n",
    "def transcribe_audio_file(filepath):\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing {filepath.name}...\")\n",
    "        result = model.transcribe(str(filepath), language=\"auto\")\n",
    "        return {\n",
    "            \"filename\": filepath.name,\n",
    "            \"text\": result[\"text\"].strip(),\n",
    "            \"language\": result.get(\"language\", \"unknown\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed on {filepath.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "results = []\n",
    "\n",
    "for audio_file in Path(audio_dir).glob(\"*.[mw][ap][34]\"):  # .mp3, .mp4, .wav\n",
    "    result = transcribe_audio_file(audio_file)\n",
    "    if result:\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3377eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# üìÑ Step 6: Save as CSV and plain text\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "csv_path = f\"{output_dir}transcripts_{timestamp}.csv\"\n",
    "txt_path = f\"{output_dir}corpus_text_{timestamp}.txt\"\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Export only transcript text to plain .txt file\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in results:\n",
    "        f.write(row[\"text\"] + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Transcription complete.\")\n",
    "print(f\"üìù CSV saved to: {csv_path}\")\n",
    "print(f\"üìÑ Plain text saved to: {txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0ddd2",
   "metadata": {},
   "source": [
    "üî§ What This Notebook Produces\n",
    "transcripts_YYYYMMDD.csv\n",
    "‚Üí A CSV file with filename, transcript, and detected language.\n",
    "\n",
    "corpus_text_YYYYMMDD.txt\n",
    "‚Üí A clean plain-text file ready for inclusion in LLM fine-tuning datasets.\n",
    "\n",
    "üßæ Recommendations for Ethical Audio Use\n",
    "Add a consent_form_template.md in ethics-protocols/ for contributors.\n",
    "\n",
    "Use the language column to filter outputs for only Kanien'k√©ha or your target language.\n",
    "\n",
    "Encourage Elders or fluent speakers to review transcripts before inclusion in training sets.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
