{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2b3b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: After clicking the save button:\n",
    "\n",
    "* config/training_config.yaml will be created\n",
    "* Ready to validate with config_loader.py\n",
    "* Ready to train your dialect-specific LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814274b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "metadata_path = Path(\"../datasets/sample_dataset_metadata.json\")\n",
    "tokenizer_path = Path(\"../tokenizer/custom_tokenizer.json\")\n",
    "output_path = Path(\"../config/training_config.yaml\")\n",
    "\n",
    "with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6e3ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "language = widgets.Text(value=meta[\"language\"], description=\"Language\")\n",
    "dialect = widgets.Dropdown(options=[\"Eastern\", \"Central\", \"Western\", \"English Phonetics\"], value=meta[\"dialect\"], description=\"Dialect\")\n",
    "version = widgets.Text(value=meta[\"version\"], description=\"Version\")\n",
    "run_id = widgets.Text(value=f\"{meta['dialect'].lower()}-llm-qlora-v1\", description=\"Run ID\")\n",
    "tokenizer_path_display = widgets.Text(value=str(tokenizer_path), description=\"Tokenizer Path\", layout=widgets.Layout(width=\"95%\"))\n",
    "\n",
    "display(language, dialect, version, run_id, tokenizer_path_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be2360",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = widgets.Text(value=\"../datasets/kanienkeha_prefixes.jsonl\", description=\"Dataset Path\", layout=widgets.Layout(width=\"95%\"))\n",
    "batch_size = widgets.IntSlider(value=2, min=1, max=16, description=\"Batch Size\")\n",
    "epochs = widgets.IntSlider(value=3, min=1, max=10, description=\"Epochs\")\n",
    "learning_rate = widgets.FloatSlider(value=2e-4, min=1e-5, max=1e-3, step=1e-5, description=\"Learning Rate\")\n",
    "gradient_steps = widgets.IntSlider(value=8, min=1, max=64, description=\"Grad Steps\")\n",
    "\n",
    "display(dataset_path, batch_size, epochs, learning_rate, gradient_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec396cf9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ethics_worksheet = widgets.Text(value=\"../ethics-protocols/ethics_team_input.csv\", description=\"Ethics CSV\", layout=widgets.Layout(width=\"95%\"))\n",
    "offline_mode = widgets.Checkbox(value=True, description=\"Allow Offline Mode\")\n",
    "\n",
    "display(ethics_worksheet, offline_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccf7fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "save_btn = widgets.Button(description=\"Generate training_config.yaml\", button_style=\"success\")\n",
    "\n",
    "def on_save_clicked(b):\n",
    "    config = {\n",
    "        \"project_name\": \"mini-indig-llm-kit\",\n",
    "        \"language\": language.value,\n",
    "        \"dialect\": dialect.value,\n",
    "        \"version\": version.value,\n",
    "        \"run_id\": run_id.value,\n",
    "\n",
    "        \"base_model\": {\n",
    "            \"name\": \"meta-llama/Llama-3-8B\",\n",
    "            \"revision\": \"main\",\n",
    "            \"quantization\": \"4bit\",\n",
    "            \"architecture\": \"llama\",\n",
    "            \"tokenizer_path\": tokenizer_path_display.value\n",
    "        },\n",
    "\n",
    "        \"trainer\": \"qlora\",\n",
    "        \"precision\": \"bf16\",\n",
    "        \"use_flash_attention\": False,\n",
    "        \"gradient_checkpointing\": True,\n",
    "\n",
    "        \"dataset\": {\n",
    "            \"name\": f\"{language.value.lower()}_{dialect.value.lower()}_dataset\",\n",
    "            \"path\": dataset_path.value,\n",
    "            \"metadata\": str(metadata_path),\n",
    "            \"format\": \"jsonl\",\n",
    "            \"text_field\": \"text\",\n",
    "            \"max_seq_length\": 2048,\n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 2,\n",
    "            \"tokenization_rules\": \"../tokenizer/kanienkeha_vocab_rules.yaml\"\n",
    "        },\n",
    "\n",
    "        \"training\": {\n",
    "            \"epochs\": epochs.value,\n",
    "            \"batch_size\": batch_size.value,\n",
    "            \"gradient_accumulation_steps\": gradient_steps.value,\n",
    "            \"learning_rate\": learning_rate.value,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"warmup_steps\": 20,\n",
    "            \"logging_steps\": 10,\n",
    "            \"save_steps\": 50,\n",
    "            \"eval_steps\": 25,\n",
    "            \"seed\": 42\n",
    "        },\n",
    "\n",
    "        \"output\": {\n",
    "            \"output_dir\": f\"../models/{dialect.value.lower()}_llm\",\n",
    "            \"model_card\": \"../models/generated_model_card.md\",\n",
    "            \"save_total_limit\": 2,\n",
    "            \"save_strategy\": \"steps\",\n",
    "            \"eval_strategy\": \"steps\"\n",
    "        },\n",
    "\n",
    "        \"offline\": {\n",
    "            \"tokenizer_cache\": \"../tokenizer/\",\n",
    "            \"model_cache\": \"../models/base/\",\n",
    "            \"allow_offline_mode\": offline_mode.value\n",
    "        },\n",
    "\n",
    "        \"evaluation\": {\n",
    "            \"enabled\": True,\n",
    "            \"notebook\": \"../notebooks/5_evaluation_metrics.ipynb\",\n",
    "            \"metrics\": [\n",
    "                \"exact_match\",\n",
    "                \"morpheme_accuracy\",\n",
    "                \"prefix_precision\",\n",
    "                \"custom_speaker_validation\"\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        \"ethics\": {\n",
    "            \"worksheet_path\": ethics_worksheet.value,\n",
    "            \"respect_data_sovereignty\": True,\n",
    "            \"require_contributor_consent\": True,\n",
    "            \"dialect_guidelines_path\": \"../ethics-protocols/dialect_ethics.md\"\n",
    "        },\n",
    "\n",
    "        \"collaboration\": {\n",
    "            \"contributors_file\": str(metadata_path),\n",
    "            \"editable_notes\": \"../ethics-protocols/notes_by_team.csv\",\n",
    "            \"session_tracking\": \"enabled\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.dump(config, f, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "    print(f\"âœ… training_config.yaml written to {output_path}\")\n",
    "\n",
    "save_btn.on_click(on_save_clicked)\n",
    "display(save_btn)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
