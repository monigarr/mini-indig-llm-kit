{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986bfe3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#\n",
    "# tokenizer_segmentation_scores.ipynb\n",
    "# Here is a complete and user-friendly Jupyter Notebook designed for language teams and developers to:\n",
    "# ‚úÖ Run tokenizer segmentation tests from a .csv\n",
    "# ‚úÖ Compute precision, recall, and F1 score\n",
    "# ‚úÖ Visualize token-by-token comparison\n",
    "# ‚úÖ Highlight mismatches for easy human review\n",
    "# ‚úÖ Export results to .ods (LibreOffice) and .html formats\n",
    "#\n",
    "# Author: \n",
    "#   MoniGarr (Monica Peters), monigarr@MoniGarr.com\n",
    "#\n",
    "# This repository supports language revival & retention for\n",
    "#     Polysynthetic, Low-Resource Indigenous Languages that\n",
    "#       might lack industry standard language ISO codes.\n",
    "#\n",
    "# License: Apache 2.0\n",
    "# \n",
    "# For technical consulting, collaboration, or mentorship on Indigenous\n",
    "# Language Revival & Retention Tech Solutions (AI, XR, 3D, Cultural Protocols)\n",
    "# contact:\n",
    "#   MoniGarr (Monica Peters) ‚Äì monigarr@monigarr.com\n",
    "#   Founder of MoniGarr.com LLC and MohawkLanguage.ca\n",
    "#   Akwesasne-based Onkwehonwe (Indigenous, Kanien‚Äôk√©hake, Mohawk of Akwesasne)\n",
    "#   https://www.linkedin.com/in/3dtechartist\n",
    "#\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c609a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "üß† Features Summary\n",
    "Feature\t                            Included ‚úÖ\n",
    "Token-by-token comparison\t                ‚úÖ\n",
    "Precision, Recall, F1 per sentence\t        ‚úÖ\n",
    "Visual diff highlighting (HTML)\t            ‚úÖ\n",
    "ODS export for offline Elders\t            ‚úÖ\n",
    "HTML export for easy review\t                ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8defec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìì tokenizer_segmentation_scores.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import difflib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3b0c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üîß CONFIG\n",
    "csv_path = \"../tokenizer/tests/tokenizer_test_set.csv\"\n",
    "tokenizer_path = \"../tokenizer/custom_tokenizer.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2bd81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìö Load data\n",
    "df = pd.read_csv(csv_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d980a41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# URL encode helper\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f56261",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìä Prepare result table\n",
    "github_org = \"monigarr\"\"\n",
    "github_repo = \"mini-indig-llm-kit\"\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    case_id = row[\"id\"]\n",
    "    dialect = row[\"dialect\"]\n",
    "    input_text = row[\"input\"]\n",
    "    expected_tokens = [tok.strip() for tok in row[\"expected_tokens\"].split(\",\")]\n",
    "    predicted_tokens = tokenizer.tokenize(input_text)\n",
    "\n",
    "    # Scoring\n",
    "    true_set = set(expected_tokens)\n",
    "    pred_set = set(predicted_tokens)\n",
    "    tp = len(true_set & pred_set)\n",
    "    fp = len(pred_set - true_set)\n",
    "    fn = len(true_set - pred_set)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "\n",
    "    # üîç Diff with HTML highlight\n",
    "    matcher = difflib.SequenceMatcher(None, expected_tokens, predicted_tokens)\n",
    "    diff_html = \"\"\n",
    "    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
    "        if opcode == 'equal':\n",
    "            diff_html += \" \".join([f\"<span style='color:green'>{tok}</span>\" for tok in expected_tokens[a0:a1]]) + \" \"\n",
    "        else:\n",
    "            diff_html += \" \".join([f\"<span style='color:red'>{tok}</span>\" for tok in expected_tokens[a0:a1]]) + \" \"\n",
    "            diff_html += \" \".join([f\"<span style='color:orange'>{tok}</span>\" for tok in predicted_tokens[b0:b1]]) + \" \"\n",
    "\n",
    "    # üìù Add annotation link\n",
    "    issue_title = f\"Annotation for Test {case_id}\"\n",
    "    issue_body = (\n",
    "        f\"**Input:** {input_text}\\n\"\n",
    "        f\"**Expected Tokens:** {', '.join(expected_tokens)}\\n\"\n",
    "        f\"**Predicted Tokens:** {', '.join(predicted_tokens)}\\n\"\n",
    "        f\"**Dialect:** {dialect}\"\n",
    "    )\n",
    "    issue_url = (\n",
    "        f\"https://github.com/{github_org}/{github_repo}/issues/new?\"\n",
    "        f\"title={quote(issue_title)}&body={quote(issue_body)}\"\n",
    "    )\n",
    "    annotation_link = f\"\"\"<br><a href=\"{issue_url}\" target=\"_blank\" rel=\"noopener\" style=\"font-size:small;\">\n",
    "    üìù Suggest correction</a>\"\"\"\n",
    "\n",
    "    results.append({\n",
    "        \"ID\": case_id,\n",
    "        \"Dialect\": dialect,\n",
    "        \"Input\": input_text,\n",
    "        \"Expected\": \", \".join(expected_tokens),\n",
    "        \"Predicted\": \", \".join(predicted_tokens),\n",
    "        \"Diff Highlight\": diff_html + annotation_link,\n",
    "        \"Precision\": round(precision, 2),\n",
    "        \"Recall\": round(recall, 2),\n",
    "        \"F1\": round(f1, 2)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608874b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìà Display Scores\n",
    "results_df[[\"ID\", \"Dialect\", \"Precision\", \"Recall\", \"F1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be28d6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display all annotated rows\n",
    "display(HTML(results_df[[\"ID\", \"Input\", \"Diff Highlight\"]].to_html(escape=False, index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301efdf8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üñºÔ∏è HTML Render\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(results_df[[\"ID\", \"Input\", \"Diff Highlight\"]].to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e192ed5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üßæ EXPORTS\n",
    "\n",
    "# Plain CSV for tech review\n",
    "results_df.to_csv(\"../tokenizer/tests/segmentation_results.csv\", index=False)\n",
    "\n",
    "# LibreOffice Version for Language Teams\n",
    "results_df.to_excel(\"../tokenizer/tests/segmentation_results.ods\", index=False)\n",
    "\n",
    "# Visual diff to share / view in browser\n",
    "results_df.to_html(\"../tokenizer/tests/segmentation_results.html\", escape=False, index=False)\n",
    "\n",
    "print(\"‚úÖ Exported results to CSV, ODS, and HTML formats.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
