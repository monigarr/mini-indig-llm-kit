{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d9cb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "#\n",
    "# tokenizer_tests.ipynb\n",
    "# An interactive visualization notebook for sentence â†’ morpheme segmentations.\n",
    "#\n",
    "# Author: \n",
    "#   MoniGarr (Monica Peters), monigarr@MoniGarr.com\n",
    "#\n",
    "# This repository supports language revival & retention for\n",
    "#     Polysynthetic, Low-Resource Indigenous Languages that\n",
    "#       might lack industry standard language ISO codes.\n",
    "#\n",
    "# License: Apache 2.0\n",
    "# \n",
    "# For technical consulting, collaboration, or mentorship on Indigenous\n",
    "# Language Revival & Retention Tech Solutions (AI, XR, 3D, Cultural Protocols)\n",
    "# contact:\n",
    "#   MoniGarr (Monica Peters) â€“ monigarr@monigarr.com\n",
    "#   Founder of MoniGarr.com LLC and MohawkLanguage.ca\n",
    "#   Akwesasne-based Onkwehonwe (Indigenous, Kanienâ€™kÃ©hake, Mohawk of Akwesasne)\n",
    "#   https://www.linkedin.com/in/3dtechartist\n",
    "#\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167c557",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸ““ tokenizer_tests.ipynb\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4c20b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load tokenizer\n",
    "tokenizer_path = \"../tokenizer/custom_tokenizer.json\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23305136",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load test cases\n",
    "with open(\"../tokenizer/tests/tokenizer_test_set.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3514a32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visual test\n",
    "results = []\n",
    "for case in test_data:\n",
    "    input_text = case[\"input\"]\n",
    "    expected = case[\"expected_tokens\"]\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    results.append({\n",
    "        \"Dialect\": case[\"dialect\"],\n",
    "        \"Input\": input_text,\n",
    "        \"Expected Tokens\": expected,\n",
    "        \"Tokenized Output\": tokens,\n",
    "        \"Match\": tokens == expected\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e0196",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display as DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df.style.applymap(lambda x: \"background-color: #aaffaa\" if x is True else \"background-color: #ffaaaa\", subset=[\"Match\"])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
